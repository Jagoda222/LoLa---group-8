{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBwc38rePJmloTEFOjG9YR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jagoda222/LoLa---group-8/blob/main/dataset_triplets_1000.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sampling 10,000 Triplets from SNLI Dataset\n",
        "\n",
        "This notebook demonstrates how to preprocess the SNLI dataset and sample **10,000 triplets** (30,000 rows). Each triplet consists of:\n",
        "- One **premise** shared by three rows.\n",
        "- Three **hypotheses** corresponding to labels `0` (entailment), `1` (neutral), and `2` (contradiction).\n",
        "\n",
        "**Steps:**\n",
        "1. Load the SNLI dataset\n",
        "2. Assign unique **triplet numbers** to valid triplets (groups of three rows with the same premise).\n",
        "3. Divide dataset into **10 equal-sized blocks** and randomly sample **1000 triplets** per block.\n",
        "4. Combine sampled triplets and save the final dataset as `sampled_snli_triplets_10000.csv`.\n",
        "\n",
        "This ensures uniform distribution and a clean triplet structure for further analysis."
      ],
      "metadata": {
        "id": "pOjp2kEvVgCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaT-osrcEvoX",
        "outputId": "95050fc9-81d9-487c-88ef-4978aed7479d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "RJv_Pa_8EW_7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the dataset"
      ],
      "metadata": {
        "id": "vjRstrM3bICG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"snli\")\n",
        "train_data = dataset['train'].to_pandas()\n",
        "\n",
        "# Rename columns for clarity\n",
        "train_data = train_data.rename(columns={\n",
        "    'sentence1': 'premise',\n",
        "    'sentence2': 'hypothesis',\n",
        "    'gold_label': 'label'\n",
        "})\n",
        "\n",
        "train_data = train_data[train_data['label'].notnull()]\n",
        "print(train_data.head())\n",
        "print(train_data.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmKkLGKcGT15",
        "outputId": "b401f805-41a0-439f-f03d-23349674c4a6"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             premise  \\\n",
            "0  A person on a horse jumps over a broken down a...   \n",
            "1  A person on a horse jumps over a broken down a...   \n",
            "2  A person on a horse jumps over a broken down a...   \n",
            "3              Children smiling and waving at camera   \n",
            "4              Children smiling and waving at camera   \n",
            "\n",
            "                                          hypothesis  label  \n",
            "0  A person is training his horse for a competition.      1  \n",
            "1      A person is at a diner, ordering an omelette.      2  \n",
            "2                  A person is outdoors, on a horse.      0  \n",
            "3                  They are smiling at their parents      1  \n",
            "4                         There are children present      0  \n",
            "               label\n",
            "count  550152.000000\n",
            "mean        0.996730\n",
            "std         0.819796\n",
            "min        -1.000000\n",
            "25%         0.000000\n",
            "50%         1.000000\n",
            "75%         2.000000\n",
            "max         2.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking the label distribution"
      ],
      "metadata": {
        "id": "9k1Dsy0XbC_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_labels = train_data['label'].unique()\n",
        "print(\"Unique label types:\", unique_labels)\n",
        "\n",
        "label_counts = train_data['label'].value_counts()\n",
        "print(\"\\nLabel counts:\")\n",
        "print(label_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zn8mm8lBOteD",
        "outputId": "deda8c72-fbcc-495a-f477-a644615b1195"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique label types: [ 1  2  0 -1]\n",
            "\n",
            "Label counts:\n",
            "label\n",
            " 0    183416\n",
            " 2    183187\n",
            " 1    182764\n",
            "-1       785\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking triplets with -1 label"
      ],
      "metadata": {
        "id": "teGezKHLbQVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter rows with label -1 in train_data\n",
        "rows_with_neg1 = train_data[train_data['label'] == -1]\n",
        "\n",
        "# Get unique premises that have at least one label -1\n",
        "premises_with_neg1 = rows_with_neg1['premise'].unique()\n",
        "\n",
        "# Filter train_data to include all rows for these premises\n",
        "all_rows_for_neg1_premises = train_data[train_data['premise'].isin(premises_with_neg1)]\n",
        "\n",
        "# Print the premises and their hypotheses\n",
        "print(\"Premises with label -1 and their hypotheses:\")\n",
        "print(all_rows_for_neg1_premises.head(9))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSvagAXrZFNF",
        "outputId": "73e99228-ce55-408e-a15f-f0b22194b373"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Premises with label -1 and their hypotheses:\n",
            "                                                premise  \\\n",
            "144   A small group of church-goers watch a choir pr...   \n",
            "145   A small group of church-goers watch a choir pr...   \n",
            "146   A small group of church-goers watch a choir pr...   \n",
            "783   A woman wearing a pink hat is looking at a pin...   \n",
            "784   A woman wearing a pink hat is looking at a pin...   \n",
            "785   A woman wearing a pink hat is looking at a pin...   \n",
            "1560  man in red canada shirt standing with three me...   \n",
            "1561  man in red canada shirt standing with three me...   \n",
            "1562  man in red canada shirt standing with three me...   \n",
            "\n",
            "                                             hypothesis  label  \n",
            "144                         A group watches a practice.      0  \n",
            "145          A choir performs in front of packed crowd.     -1  \n",
            "146   The pastor and elders watch the choir to make ...      1  \n",
            "783                       The woman is wearing clothes.     -1  \n",
            "784    The woman is wondering if she left her car open.      1  \n",
            "785      The woman is wearing a grocery bag to her car.      2  \n",
            "1560                                   Man eating pizza      2  \n",
            "1561        Man standing with three men in army uniform      0  \n",
            "1562  Man standing with three men in army uniform ne...     -1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Assigning number to each triplet"
      ],
      "metadata": {
        "id": "jtL5X427bYo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "triplet_nr = 1\n",
        "triplet_numbers = []\n",
        "\n",
        "# Iterate through the dataset in groups of three rows\n",
        "for i in range(0, len(train_data), 3):\n",
        "    group = train_data.iloc[i:i+3]\n",
        "\n",
        "    # Check if all three rows share the same premise\n",
        "    if len(group['premise'].unique()) == 1 and len(group) == 3:\n",
        "        triplet_numbers.extend([triplet_nr] * 3)\n",
        "        triplet_nr += 1\n",
        "    else:\n",
        "        triplet_numbers.extend([None] * len(group))\n",
        "\n",
        "# Assign triplet numbers to the train_data\n",
        "train_data['triplet_nr'] = triplet_numbers\n",
        "\n",
        "# Drop rows without valid triplet assignment (optional, if you only want valid triplets)\n",
        "train_data = train_data.dropna(subset=['triplet_nr'])\n",
        "\n",
        "# Convert 'triplet_nr' to integer\n",
        "train_data['triplet_nr'] = train_data['triplet_nr'].astype(int)\n",
        "\n",
        "# Print the first few rows\n",
        "print(train_data.head(9))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFYJjPhEP_PV",
        "outputId": "4789cc14-8ca5-45c4-d1c0-0c4c24789bfa"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             premise  \\\n",
            "0  A person on a horse jumps over a broken down a...   \n",
            "1  A person on a horse jumps over a broken down a...   \n",
            "2  A person on a horse jumps over a broken down a...   \n",
            "3              Children smiling and waving at camera   \n",
            "4              Children smiling and waving at camera   \n",
            "5              Children smiling and waving at camera   \n",
            "6  A boy is jumping on skateboard in the middle o...   \n",
            "7  A boy is jumping on skateboard in the middle o...   \n",
            "8  A boy is jumping on skateboard in the middle o...   \n",
            "\n",
            "                                          hypothesis  label  triplet_nr  \n",
            "0  A person is training his horse for a competition.      1           1  \n",
            "1      A person is at a diner, ordering an omelette.      2           1  \n",
            "2                  A person is outdoors, on a horse.      0           1  \n",
            "3                  They are smiling at their parents      1           2  \n",
            "4                         There are children present      0           2  \n",
            "5                              The kids are frowning      2           2  \n",
            "6                  The boy skates down the sidewalk.      2           3  \n",
            "7                The boy does a skateboarding trick.      0           3  \n",
            "8               The boy is wearing safety equipment.      1           3  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-114-7afbb70c6cba>:22: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_data['triplet_nr'] = train_data['triplet_nr'].astype(int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking if the numbers of triplets were assigned correctly to the ones with label -1"
      ],
      "metadata": {
        "id": "7csBvwodbxP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Verify that train_data contains rows with label = -1\n",
        "print(\"Unique labels in train_data:\", train_data['label'].unique())\n",
        "\n",
        "# Step 2: Extract triplets with label = -1\n",
        "triplets_with_neg1 = train_data[train_data['label'] == -1]['triplet_nr'].unique()\n",
        "\n",
        "print(f\"Total number of triplets containing label -1: {len(triplets_with_neg1)}\")\n",
        "\n",
        "# Step 3: Display the first 3 triplets containing label -1\n",
        "triplets_with_neg1_data = train_data[train_data['triplet_nr'].isin(triplets_with_neg1)]\n",
        "\n",
        "print(\"First 3 triplets containing at least one row with label -1:\")\n",
        "for triplet_nr in triplets_with_neg1[:3]:\n",
        "    print(f\"\\nTriplet Number: {triplet_nr}\")\n",
        "    print(triplets_with_neg1_data[triplets_with_neg1_data['triplet_nr'] == triplet_nr])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFItoJi9YdYb",
        "outputId": "6431e007-9161-423d-92fb-afa6e332ba62"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique labels in train_data: [ 1  2  0 -1]\n",
            "Total number of triplets containing label -1: 785\n",
            "First 3 triplets containing at least one row with label -1:\n",
            "\n",
            "Triplet Number: 49\n",
            "                                               premise  \\\n",
            "144  A small group of church-goers watch a choir pr...   \n",
            "145  A small group of church-goers watch a choir pr...   \n",
            "146  A small group of church-goers watch a choir pr...   \n",
            "\n",
            "                                            hypothesis  label  triplet_nr  \n",
            "144                        A group watches a practice.      0          49  \n",
            "145         A choir performs in front of packed crowd.     -1          49  \n",
            "146  The pastor and elders watch the choir to make ...      1          49  \n",
            "\n",
            "Triplet Number: 262\n",
            "                                               premise  \\\n",
            "783  A woman wearing a pink hat is looking at a pin...   \n",
            "784  A woman wearing a pink hat is looking at a pin...   \n",
            "785  A woman wearing a pink hat is looking at a pin...   \n",
            "\n",
            "                                           hypothesis  label  triplet_nr  \n",
            "783                     The woman is wearing clothes.     -1         262  \n",
            "784  The woman is wondering if she left her car open.      1         262  \n",
            "785    The woman is wearing a grocery bag to her car.      2         262  \n",
            "\n",
            "Triplet Number: 521\n",
            "                                                premise  \\\n",
            "1560  man in red canada shirt standing with three me...   \n",
            "1561  man in red canada shirt standing with three me...   \n",
            "1562  man in red canada shirt standing with three me...   \n",
            "\n",
            "                                             hypothesis  label  triplet_nr  \n",
            "1560                                   Man eating pizza      2         521  \n",
            "1561        Man standing with three men in army uniform      0         521  \n",
            "1562  Man standing with three men in army uniform ne...     -1         521  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chosing 100 random triplets containing -1 label\n"
      ],
      "metadata": {
        "id": "AgtJScW4fBWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly sample 100 triplets with label -1\n",
        "sampled_triplets_with_neg1 = train_data[train_data['triplet_nr'].isin(\n",
        "    np.random.choice(triplets_with_neg1, 100, replace=False)\n",
        ")]\n"
      ],
      "metadata": {
        "id": "tCMNTOA4ecrJ"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dividing dataset (without triplets with -1 label) in 10 blocks. Choosing 990 random triplets from each block. Combining triplets with and without -1 label."
      ],
      "metadata": {
        "id": "JupRv7jGfWgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_blocks = 10\n",
        "triplets_per_block = 990\n",
        "\n",
        "unique_triplets = train_data['triplet_nr'].unique()\n",
        "triplets_without_neg1 = np.setdiff1d(unique_triplets, triplets_with_neg1)\n",
        "\n",
        "# Calculate the size of each block\n",
        "num_triplets = len(unique_triplets)\n",
        "block_size = num_triplets // num_blocks\n",
        "\n",
        "sampled_triplets = []\n",
        "\n",
        "for i in range(num_blocks):\n",
        "    start_idx = i * block_size\n",
        "    end_idx = (i + 1) * block_size if i < num_blocks - 1 else num_triplets\n",
        "\n",
        "    block_triplets = unique_triplets[start_idx:end_idx]\n",
        "\n",
        "    block_triplets_without_neg1 = np.intersect1d(block_triplets, triplets_without_neg1)\n",
        "\n",
        "    sampled_without_neg1 = train_data[train_data['triplet_nr'].isin(block_triplets_without_neg1)]\n",
        "    sampled_without_neg1 = sampled_without_neg1['triplet_nr'].drop_duplicates().sample(\n",
        "        n=triplets_per_block, random_state=42\n",
        "    )\n",
        "    sampled_without_neg1 = train_data[train_data['triplet_nr'].isin(sampled_without_neg1)]\n",
        "    sampled_triplets.append(sampled_without_neg1)\n",
        "\n",
        "# Combine sampled triplets without label -1\n",
        "sampled_triplets_without_neg1 = pd.concat(sampled_triplets)\n",
        "\n",
        "# Merge the two sampled datasets\n",
        "final_sampled_data = pd.concat([sampled_triplets_with_neg1, sampled_triplets_without_neg1]).reset_index(drop=True)\n",
        "\n",
        "print(f\"Total number of triplets chosen: {final_sampled_data['triplet_nr'].nunique()}\")\n",
        "print(\"\\nLabel distribution in the sampled data:\")\n",
        "print(final_sampled_data['label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOXjaqfCeB1e",
        "outputId": "5795c930-b1b1-4c23-db14-90b9bc30b0f0"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of triplets chosen: 10000\n",
            "\n",
            "Label distribution in the sampled data:\n",
            "label\n",
            " 2    10008\n",
            " 0     9958\n",
            " 1     9934\n",
            "-1      100\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_sampled_data.to_csv('sampled_snli_10000.csv', index=False)\n"
      ],
      "metadata": {
        "id": "dIUGB8TJf5H-"
      },
      "execution_count": 139,
      "outputs": []
    }
  ]
}