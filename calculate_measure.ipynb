{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jagoda222/LoLa---group-8/blob/main/calculate_measure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXAKUCitXzob"
      },
      "source": [
        "# Measure calculation and sampling the data (700 triplets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6DeRwL0XjDV",
        "outputId": "0a412f99-2cd3-40e5-e26a-c75d20f7c1d7"
      },
      "outputs": [],
      "source": [
        "!pip install -U datasets\n",
        "!pip install evaluate\n",
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_md\n",
        "!pip install syllapy\n",
        "#!pip install stanza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPd1ABy74HLL",
        "outputId": "649be76d-692e-45c6-9023-bad37e2dd876"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CjUbKdCJnYSu"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\David\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sentence_transformers'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer, util\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer, util\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sentence_transformers'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "#from datasets import load_dataset, load_metric, concatenate_datasets\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from transformers import EarlyStoppingCallback\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import spacy\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "import nltk\n",
        "import syllapy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_md\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBatkJpGDWlB"
      },
      "source": [
        "## Function for sampling based on the measure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "PNH7S7BMnVXv"
      },
      "outputs": [],
      "source": [
        "def process_snli_dataset_with_measures(file_path, sample_size=700, num_bins=7, measures=None):\n",
        "    \"\"\"\n",
        "    Process an SNLI dataset for curriculum learning with one measure at a time, proportional sampling, and random baseline.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the CSV file containing the dataset.\n",
        "        sample_size (int): The number of triplets to sample from the dataset. Default is 700.\n",
        "        num_bins (int): Number of bins for dividing measure values. Default is 7.\n",
        "        measures (list): List of functions to calculate complexity measures.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing increasing, decreasing, and random baseline DataFrames for each measure.\n",
        "    \"\"\"\n",
        "\n",
        "    # Step 1: Load dataset\n",
        "    data = pd.read_csv(file_path)\n",
        "    print(f\"Dataset loaded: {len(data)} rows\")\n",
        "\n",
        "    data['premise'] = data['premise'].fillna(\"\").astype(str)\n",
        "    data['hypothesis'] = data['hypothesis'].fillna(\"\").astype(str)\n",
        "\n",
        "    # Store results\n",
        "    result = {}\n",
        "\n",
        "    # Step 2: Process for each measure separately\n",
        "    for idx, measure_func in enumerate(measures):\n",
        "        measure_name = measure_func.__name__\n",
        "\n",
        "        # Calculate the measure for each row\n",
        "        data[measure_name] = data.apply(measure_func, axis=1)\n",
        "\n",
        "        # Step 3: Calculate triplet-level averages for the current measure\n",
        "        triplet_avg = data.groupby('triplet_nr')[measure_name].mean().reset_index(name='triplet_avg')\n",
        "\n",
        "        # Step 4: Bin triplets based on the current measure's triplet average\n",
        "        bin_edges = np.linspace(triplet_avg['triplet_avg'].min(), triplet_avg['triplet_avg'].max(), num_bins + 1)\n",
        "        triplet_avg['range_bin'] = pd.cut(triplet_avg['triplet_avg'], bins=bin_edges, labels=False, include_lowest=True)\n",
        "\n",
        "        # Step 5: Calculate how many triplets to sample from each bin\n",
        "        bin_distribution = triplet_avg['range_bin'].value_counts().sort_index()\n",
        "        print(f\"\\nDistribution of triplets across bins for {measure_name}:\\n{bin_distribution}\")\n",
        "\n",
        "        triplets_per_bin = (bin_distribution / bin_distribution.sum() * sample_size).astype(int)\n",
        "\n",
        "        # Adjust sample size if needed\n",
        "        while triplets_per_bin.sum() < sample_size:\n",
        "            residuals = (bin_distribution / bin_distribution.sum() * sample_size) - triplets_per_bin\n",
        "            triplets_per_bin[residuals.idxmax()] += 1\n",
        "\n",
        "        while triplets_per_bin.sum() > sample_size:\n",
        "            residuals = (bin_distribution / bin_distribution.sum() * sample_size) - triplets_per_bin\n",
        "            triplets_per_bin[residuals.idxmin()] -= 1\n",
        "\n",
        "        # Step 6: Sample triplets proportionally from each bin\n",
        "        sampled_triplets = []\n",
        "        for bin_id, sample_count in triplets_per_bin.items():\n",
        "            if sample_count > 0:\n",
        "                triplets_in_bin = triplet_avg[triplet_avg['range_bin'] == bin_id]['triplet_nr'].values\n",
        "                sampled_triplet_ids = np.random.choice(triplets_in_bin, size=min(sample_count, len(triplets_in_bin)), replace=False)\n",
        "                sampled_triplets.append(data[data['triplet_nr'].isin(sampled_triplet_ids)])\n",
        "\n",
        "        # Combine sampled triplets into a single DataFrame\n",
        "        final_sample = pd.concat(sampled_triplets).reset_index(drop=True)\n",
        "\n",
        "        # Step 7: Merge back the triplet averages\n",
        "        final_sample = final_sample.merge(triplet_avg[['triplet_nr', 'triplet_avg']], on='triplet_nr')\n",
        "\n",
        "        # Step 8: Sort by increasing and decreasing order\n",
        "        final_sample_increasing = final_sample.sort_values(by='triplet_avg').reset_index(drop=True)\n",
        "        final_sample_decreasing = final_sample.sort_values(by='triplet_avg', ascending=False).reset_index(drop=True)\n",
        "        baseline = final_sample.sample(frac=1, random_state=100)\n",
        "\n",
        "\n",
        "        # Store results for this measure\n",
        "        result[measure_name] = {\n",
        "            'increasing': final_sample_increasing,\n",
        "            'decreasing': final_sample_decreasing,\n",
        "            'baseline': baseline\n",
        "        }\n",
        "\n",
        "    print(f\"Processed {sample_size} triplets and returned ordered DataFrames for each measure.\")\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOGJhk7CDQC9"
      },
      "source": [
        "## Measure 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42Xj6HJAhb93",
        "outputId": "55574c57-8858-4ccc-d124-d9ab676f944f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum sentence length: 78\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/sampled_snli_10000.csv'  # Update the path if needed\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Calculate sentence lengths\n",
        "df['premise_length'] = df['premise'].apply(lambda x: len(str(x).split()))\n",
        "df['hypothesis_length'] = df['hypothesis'].apply(lambda x: len(str(x).split()))\n",
        "\n",
        "# Find the maximum sentence length between both columns\n",
        "max_length = max(df['premise_length'].max(), df['hypothesis_length'].max())\n",
        "\n",
        "print(\"Maximum sentence length:\", max_length)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "WVytZqVUTXZM"
      },
      "outputs": [],
      "source": [
        "def measure_1(row):\n",
        "    \"\"\"Calculate combined complexity score using syntactic overlap, lexical diversity, and sentence length.\"\"\"\n",
        "\n",
        "    # Extract premise and hypothesis from the row\n",
        "    premise = row['premise']\n",
        "    hypothesis = row['hypothesis']\n",
        "\n",
        "    def longest_common_subsequence(X, Y):\n",
        "        \"\"\"Calculate the length of the longest common subsequence between two sentences.\"\"\"\n",
        "        m, n = len(X), len(Y)\n",
        "        dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
        "\n",
        "        # Fill DP table\n",
        "        for i in range(1, m + 1):\n",
        "            for j in range(1, n + 1):\n",
        "                if X[i - 1] == Y[j - 1]:\n",
        "                    dp[i][j] = dp[i - 1][j - 1] + 1\n",
        "                else:\n",
        "                    dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])\n",
        "        return dp[m][n]\n",
        "\n",
        "    def syntactic_overlap(premise, hypothesis):\n",
        "        \"\"\"Calculate syntactic overlap using longest common subsequence.\"\"\"\n",
        "        premise_words = premise.split()\n",
        "        hypothesis_words = hypothesis.split()\n",
        "        lcs_length = longest_common_subsequence(premise_words, hypothesis_words)\n",
        "        return lcs_length / max(len(premise_words), len(hypothesis_words))\n",
        "\n",
        "    def lexical_diversity_comparison(premise, hypothesis):\n",
        "        \"\"\"Calculate lexical diversity comparison between premise and hypothesis.\"\"\"\n",
        "        premise_words = set(premise.split())\n",
        "        hypothesis_words = set(hypothesis.split())\n",
        "        shared_unique_words = len(premise_words & hypothesis_words)\n",
        "        total_words = len(premise.split()) + len(hypothesis.split())\n",
        "        return shared_unique_words / total_words if total_words > 0 else 0\n",
        "\n",
        "    # Step 1: Calculate syntactic overlap (higher difference -> more complex)\n",
        "    syntactic_diff = 1 - syntactic_overlap(premise, hypothesis)\n",
        "\n",
        "    # Step 2: Calculate lexical diversity comparison (higher diversity -> more complex)\n",
        "    lexical_diversity_score = 1 - lexical_diversity_comparison(premise, hypothesis)\n",
        "\n",
        "    # Step 3: Calculate normalized sentence length\n",
        "    max_length = 78  # Maximum sentence length for normalization\n",
        "    combined_length = len(premise.split()) + len(hypothesis.split())\n",
        "    normalized_length = combined_length / max_length\n",
        "\n",
        "    # Step 4: Combine using weights\n",
        "    w1, w2, w3 = 0.5, 0.3, 0.2  # Weights for syntactic overlap, lexical diversity, and length\n",
        "    complexity_score = (w1 * syntactic_diff) + (w2 * lexical_diversity_score) + (w3 * normalized_length)\n",
        "\n",
        "    return complexity_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Syntactic Tree Depth Measure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "def compute_tree_depth(text):\n",
        " \n",
        "    def get_dependency_depth(token):\n",
        "        \"\"\"Recursively find the depth of a token in the dependency tree.\"\"\"\n",
        "        if token == token.head:  # Root node (self-referential head)\n",
        "            return 0\n",
        "        return 1 + get_dependency_depth(token.head)\n",
        "    \n",
        "    doc = nlp(text)\n",
        "\n",
        "    return max(get_dependency_depth(token) for token in doc) if len(doc) > 0 else 0\n",
        "\n",
        "def tree_depth_premise(row):\n",
        "    \"\"\"\n",
        "    Compute the tree depth for the premise of a single row.\n",
        "    \"\"\"\n",
        "    return compute_tree_depth(row[\"premise\"])\n",
        "\n",
        "def tree_depth_hypothesis(row):\n",
        "    \"\"\"\n",
        "    Compute the tree depth for the hypothesis of a single row.\n",
        "    \"\"\"\n",
        "    return compute_tree_depth(row[\"hypothesis\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sentence Length Measure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def length_calc(text):\n",
        "    \"\"\"\n",
        "    Function to calculate the number of words in a given text.\n",
        "    \"\"\"\n",
        "    return len(text.split())\n",
        "\n",
        "def sentence_length_premise(row):\n",
        "    \"\"\"\n",
        "    Compute the sentence length for the premise of a single row.\n",
        "    \"\"\"\n",
        "    return length_calc(row[\"premise\"])\n",
        "\n",
        "def sentence_length_hypothesis(row):\n",
        "    \"\"\"\n",
        "    Compute the sentence length for the hypothesis of a single row.\n",
        "    \"\"\"\n",
        "    return length_calc(row[\"hypothesis\"])\n",
        "\n",
        "def sentence_length_combined(row):\n",
        "    \"\"\"\n",
        "    Compute the combined length of the premise and hypothesis for a single row.\n",
        "    \"\"\"\n",
        "    return sentence_length_premise(row) + sentence_length_hypothesis(row)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Flesch-Kincaid Measure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def flesch_kincaid_calc(text):\n",
        "    \"\"\"\n",
        "    function to compute the Flesch-Kincaid Grade Level for a given text.\n",
        "    \"\"\"\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    words = nltk.word_tokenize(text)\n",
        "\n",
        "\n",
        "    total_words = max(len(words), 1)\n",
        "    total_sentences = max(len(sentences), 1)\n",
        "    total_syllables = sum(syllapy.count(word) for word in words)\n",
        "\n",
        "    # Flesch-Kincaid Grade Level formula\n",
        "    grade_level = 0.39 * (total_words / total_sentences) + 11.8 * (total_syllables / total_words) - 15.59\n",
        "    return round(grade_level, 2)\n",
        "\n",
        "def flesch_kincaid_premise(row):\n",
        "    \"\"\"\n",
        "    Compute the Flesch-Kincaid Grade Level for the premise of a single row.\n",
        "    \"\"\"\n",
        "    return flesch_kincaid_calc(row[\"premise\"])\n",
        "\n",
        "def flesch_kincaid_hypothesis(row):\n",
        "    \"\"\"\n",
        "    Compute the Flesch-Kincaid Grade Level for the hypothesis of a single row.\n",
        "    \"\"\"\n",
        "    return flesch_kincaid_calc(row[\"hypothesis\"])\n",
        "\n",
        "def flesch_kincaid_combined(row):\n",
        "    \"\"\"\n",
        "    Compute the combined Flesch-Kincaid Grade Level (premise + hypothesis) for a single row.\n",
        "    \"\"\"\n",
        "    return flesch_kincaid_premise(row) + flesch_kincaid_hypothesis(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SARFGcpHTZe3",
        "outputId": "7fd0c31f-bb77-4fb6-d1d2-a6032e57e6a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset loaded: 30000 rows\n",
            "\n",
            "Distribution of triplets across bins for measure_1:\n",
            "range_bin\n",
            "0     135\n",
            "1     138\n",
            "2     699\n",
            "3    2468\n",
            "4    4641\n",
            "5    1910\n",
            "6       9\n",
            "Name: count, dtype: int64\n",
            "Processed 700 triplets and returned ordered DataFrames for each measure.\n",
            "Saved measure_1 DataFrames to CSV:\n",
            "/content/measure_1_increasing.csv\n",
            "/content/measure_1_decreasing.csv\n",
            "/content/measure_1_random_baseline.csv\n"
          ]
        }
      ],
      "source": [
        "# Usage\n",
        "file_path = \"/content/sampled_snli_10000.csv\"\n",
        "measure_list = [measure_1, tree_depth_premise, tree_depth_hypothesis, sentence_length_premise,\n",
        "                sentence_length_hypothesis, sentence_length_combined, flesch_kincaid_premise,\n",
        "                flesch_kincaid_hypothesis, flesch_kincaid_combined\n",
        "                ]\n",
        "result = process_snli_dataset_with_measures(file_path, sample_size=700, num_bins=7, measures=measure_list)\n",
        "\n",
        "# Step to save increasing, decreasing, and random baseline DataFrames for each measure\n",
        "for measure_name, dataframes in result.items():\n",
        "    # Extract increasing, decreasing, and random baseline DataFrames\n",
        "    increasing_df = dataframes['increasing']\n",
        "    decreasing_df = dataframes['decreasing']\n",
        "    random_baseline_df = dataframes['baseline']\n",
        "\n",
        "    # Save to CSV\n",
        "    increasing_df.to_csv(f\"/content/{measure_name}_increasing.csv\", index=False)\n",
        "    decreasing_df.to_csv(f\"/content/{measure_name}_decreasing.csv\", index=False)\n",
        "    random_baseline_df.to_csv(f\"/content/{measure_name}_baseline.csv\", index=False)\n",
        "\n",
        "    print(f\"Saved {measure_name} DataFrames to CSV:\")\n",
        "    print(f\"/content/{measure_name}_increasing.csv\")\n",
        "    print(f\"/content/{measure_name}_decreasing.csv\")\n",
        "    print(f\"/content/{measure_name}_random_baseline.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yYDY9Z3XuOI"
      },
      "source": [
        "#Running models on the sampled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "v7W3HxdxG8BL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import load_dataset, Dataset\n",
        "from evaluate import load # Import load instead of load_metric\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386,
          "referenced_widgets": [
            "f3838291908042678d5109eec038072b",
            "87fab7b5ba4d4fd69f6135f815d1f88d",
            "41bf5f7fe2ba411e94e2338f68f4ef24",
            "8495b5a0f12e43f781265aebb3bebe44",
            "b4a196cb602d44e8bd8cdd7cb8b48f8e",
            "b33d1a7161364074a7d8249d7e5d8c8c",
            "f3e7cc29969a4ed68fd8a567eba076f3",
            "fa5978971c3445cfa2ee62ec3d5c9304",
            "6919bcbb530e49a29e42865651a5cc7f",
            "d9f9a84d750248ca9e8233af5d9c3d75",
            "c396ff2df14f4b7aacf69e7d6bff7f94",
            "88c5e0055a34407e89b395936a51a732",
            "d69857e8def847289a8f3d4d573f8a28",
            "725da50686dd4130aaa15f9336820cb9",
            "463cc4dd65584ab3a840e9104333c3a6",
            "2c6096f6853b416a8c18d9c4b6c27ecc",
            "acddc194af0a48f6bf1c64346345555f",
            "9a7b37199cb64ab5aef2efefa3b20983",
            "d61cd0a9f86c464998b95e837e403ab3",
            "df6042facb074f1fbf8bd67b88aa08dd",
            "4a753d9e67124815b212d00c12a3e906",
            "787d191de6a24c1f80bc49d886f79da1"
          ]
        },
        "id": "-gtkIaNbXr7s",
        "outputId": "a82c7aae-ca6b-45cd-f9c2-70ecba4ab2a6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3838291908042678d5109eec038072b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88c5e0055a34407e89b395936a51a732",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2100 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-25-179bc7c18e3d>:55: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='529' max='528' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [528/528 01:50, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.739600</td>\n",
              "      <td>0.540333</td>\n",
              "      <td>0.812030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.307600</td>\n",
              "      <td>0.518411</td>\n",
              "      <td>0.839870</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "MODEL_DIR = 'model_checkpoints'\n",
        "MODEL_CHECKPOINT = \"microsoft/deberta-v3-small\"\n",
        "BATCH_SIZE = 16\n",
        "FILE_TO_TRAIN = \"/content/measure_1_baseline.csv\"\n",
        "\n",
        "# Load the evaluation dataset from SNLI\n",
        "snli = load_dataset(\"snli\")\n",
        "snli = snli.filter(lambda example: example[\"label\"] >= 0)  # Filter labels directly\n",
        "\n",
        "train_dataset = load_dataset(\"csv\", data_files=FILE_TO_TRAIN)[\"train\"]\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['premise'], examples['hypothesis'], truncation=True)\n",
        "\n",
        "# Preprocess both training and validation datasets\n",
        "encoded_train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
        "encoded_snli = snli.map(preprocess_function, batched=True, load_from_cache_file=True)\n",
        "\n",
        "# Training arguments\n",
        "args = TrainingArguments(\n",
        "    output_dir=MODEL_DIR,\n",
        "    evaluation_strategy=\"steps\",  # Evaluate periodically during training\n",
        "    eval_steps=200,  # Frequency of evaluation during training\n",
        "    save_steps=200,  # Save model checkpoints periodically\n",
        "    logging_steps=100,  # Log training metrics periodically\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    learning_rate=5.1e-05,\n",
        "    num_train_epochs=4,\n",
        "    weight_decay=0.0074,\n",
        "    warmup_steps=211,\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    logging_dir=\"./logs\",\n",
        "    fp16=True,  # Enable mixed precision training\n",
        "    lr_scheduler_type=\"cosine\"\n",
        ")\n",
        "\n",
        "# Initialize model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_CHECKPOINT, num_labels=3)\n",
        "\n",
        "# Define compute_metrics function\n",
        "metric = load('glue', \"mnli\")\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "# Trainer setup\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=encoded_train_dataset,\n",
        "    eval_dataset=encoded_snli[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save final model and tokenizer\n",
        "trainer.save_model(os.path.join(MODEL_DIR, \"final_model\"))\n",
        "tokenizer.save_pretrained(os.path.join(MODEL_DIR, \"final_model\"))\n",
        "\n",
        "print(f\"Training completed. Model and tokenizer saved to: {os.path.join(MODEL_DIR, 'final_model')}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyM9OUoEAmPRA27f5jeH+Jb1",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2c6096f6853b416a8c18d9c4b6c27ecc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41bf5f7fe2ba411e94e2338f68f4ef24": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa5978971c3445cfa2ee62ec3d5c9304",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6919bcbb530e49a29e42865651a5cc7f",
            "value": 1
          }
        },
        "463cc4dd65584ab3a840e9104333c3a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a753d9e67124815b212d00c12a3e906",
            "placeholder": "​",
            "style": "IPY_MODEL_787d191de6a24c1f80bc49d886f79da1",
            "value": " 2100/2100 [00:00&lt;00:00, 5107.65 examples/s]"
          }
        },
        "4a753d9e67124815b212d00c12a3e906": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6919bcbb530e49a29e42865651a5cc7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "725da50686dd4130aaa15f9336820cb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d61cd0a9f86c464998b95e837e403ab3",
            "max": 2100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df6042facb074f1fbf8bd67b88aa08dd",
            "value": 2100
          }
        },
        "787d191de6a24c1f80bc49d886f79da1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8495b5a0f12e43f781265aebb3bebe44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9f9a84d750248ca9e8233af5d9c3d75",
            "placeholder": "​",
            "style": "IPY_MODEL_c396ff2df14f4b7aacf69e7d6bff7f94",
            "value": " 2100/0 [00:00&lt;00:00, 28497.60 examples/s]"
          }
        },
        "87fab7b5ba4d4fd69f6135f815d1f88d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b33d1a7161364074a7d8249d7e5d8c8c",
            "placeholder": "​",
            "style": "IPY_MODEL_f3e7cc29969a4ed68fd8a567eba076f3",
            "value": "Generating train split: "
          }
        },
        "88c5e0055a34407e89b395936a51a732": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d69857e8def847289a8f3d4d573f8a28",
              "IPY_MODEL_725da50686dd4130aaa15f9336820cb9",
              "IPY_MODEL_463cc4dd65584ab3a840e9104333c3a6"
            ],
            "layout": "IPY_MODEL_2c6096f6853b416a8c18d9c4b6c27ecc"
          }
        },
        "9a7b37199cb64ab5aef2efefa3b20983": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acddc194af0a48f6bf1c64346345555f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b33d1a7161364074a7d8249d7e5d8c8c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4a196cb602d44e8bd8cdd7cb8b48f8e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c396ff2df14f4b7aacf69e7d6bff7f94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d61cd0a9f86c464998b95e837e403ab3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d69857e8def847289a8f3d4d573f8a28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acddc194af0a48f6bf1c64346345555f",
            "placeholder": "​",
            "style": "IPY_MODEL_9a7b37199cb64ab5aef2efefa3b20983",
            "value": "Map: 100%"
          }
        },
        "d9f9a84d750248ca9e8233af5d9c3d75": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df6042facb074f1fbf8bd67b88aa08dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3838291908042678d5109eec038072b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87fab7b5ba4d4fd69f6135f815d1f88d",
              "IPY_MODEL_41bf5f7fe2ba411e94e2338f68f4ef24",
              "IPY_MODEL_8495b5a0f12e43f781265aebb3bebe44"
            ],
            "layout": "IPY_MODEL_b4a196cb602d44e8bd8cdd7cb8b48f8e"
          }
        },
        "f3e7cc29969a4ed68fd8a567eba076f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa5978971c3445cfa2ee62ec3d5c9304": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
