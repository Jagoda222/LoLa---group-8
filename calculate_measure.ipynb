{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMn+4mxEZ5tcNQ9p3O5lpSI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jagoda222/LoLa---group-8/blob/main/calculate_measure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This code processes an SNLI dataset for curriculum learning using proportional sampling based on a complexity measure. Here's what it does in a few steps:\n",
        "\n",
        "1. **Load and Prepare Data**:\n",
        "   - Reads a CSV file, cleans missing values, and converts text columns (`premise` and `hypothesis`) to strings.\n",
        "\n",
        "2. **Calculate Complexity Measure**:\n",
        "   - Computes given `measure_1` for each row (example -  the sum of the lengths of `premise` and `hypothesis`.)\n",
        "\n",
        "3. **Bin the Data**:\n",
        "   - Divides `measure_1` values into `num_bins` (default: 7) and assigns each triplet to a bin.\n",
        "\n",
        "4. **Proportional Sampling**:\n",
        "   - Samples `sample_size` triplets (default: 700) proportionally across the bins, ensuring no more or less (depending on the bin distribution) 700 unique triplets.\n",
        "\n",
        "5. **Sort and Return**:\n",
        "   - Calculates the average `measure_1` for each triplet and creates two DataFrames:\n",
        "     - One ordered by increasing complexity.\n",
        "     - One ordered by decreasing complexity.\n",
        "\n",
        "It ensures balanced sampling across bins and returns two ordered subsets of the data."
      ],
      "metadata": {
        "id": "2DkuuJyuvl1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "CjUbKdCJnYSu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PNH7S7BMnVXv"
      },
      "outputs": [],
      "source": [
        "def process_snli_dataset_with_measures(file_path, sample_size=700, num_bins=7):\n",
        "    \"\"\"\n",
        "    Process an SNLI dataset for curriculum learning with nested measures and proportional sampling.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the CSV file containing the dataset.\n",
        "        sample_size (int): The number of triplets to sample from the dataset. Default is 700.\n",
        "        num_bins (int): Number of bins for dividing measure_1 values. Default is 7.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Two DataFrames - one ordered by increasing average measure_1 and one by decreasing average measure_1.\n",
        "    \"\"\"\n",
        "    # Step 1:\n",
        "    data = pd.read_csv(file_path)\n",
        "    print(f\"Dataset loaded: {len(data)} rows\")\n",
        "\n",
        "    data['premise'] = data['premise'].fillna(\"\").astype(str)\n",
        "    data['hypothesis'] = data['hypothesis'].fillna(\"\").astype(str)\n",
        "\n",
        "    # Step 2: CHANGE THE MEASURE\n",
        "    def measure_1(row):\n",
        "        \"\"\"Example complexity measure: sum of lengths of premise and hypothesis.\"\"\"\n",
        "        return len(row['premise']) + len(row['hypothesis'])\n",
        "\n",
        "    data['measure_1'] = data.apply(measure_1, axis=1)\n",
        "\n",
        "    # Step 3:\n",
        "    def sample_triplets(data, sample_size, num_bins):\n",
        "        # Step 3.1: Divide measure_1 into ranges (bins)\n",
        "        bin_edges = np.linspace(data['measure_1'].min(), data['measure_1'].max(), num_bins + 1)\n",
        "        data['range_bin'] = pd.cut(data['measure_1'], bins=bin_edges, labels=False, include_lowest=True)\n",
        "\n",
        "        # Step 3.2: Calculate bin distributions\n",
        "        bin_distribution = data.groupby('range_bin')['triplet_nr'].nunique()\n",
        "        print(f\"Distribution of triplets across bins:\\n{bin_distribution}\")\n",
        "\n",
        "        # Step 3.3: Determine how many triplets to sample from each bin\n",
        "        total_triplets = data['triplet_nr'].nunique()\n",
        "        triplets_per_bin = (bin_distribution / total_triplets * sample_size).astype(int)\n",
        "\n",
        "        # Ensure the sum matches sample_size\n",
        "        while triplets_per_bin.sum() < sample_size:\n",
        "            residuals = (bin_distribution / total_triplets * sample_size) - triplets_per_bin\n",
        "            triplets_per_bin[residuals.idxmax()] += 1\n",
        "\n",
        "        while triplets_per_bin.sum() > sample_size:\n",
        "            residuals = (bin_distribution / total_triplets * sample_size) - triplets_per_bin\n",
        "            triplets_per_bin[residuals.idxmin()] -= 1\n",
        "\n",
        "        # Step 3.4: Sample triplets proportionally from each bin\n",
        "        sampled_triplets = []\n",
        "        for bin_id, sample_count in triplets_per_bin.items():\n",
        "            if sample_count > 0:\n",
        "                triplets_in_bin = data[data['range_bin'] == bin_id]['triplet_nr'].unique()\n",
        "                sampled_triplet_ids = np.random.choice(triplets_in_bin, size=min(sample_count, len(triplets_in_bin)), replace=False)\n",
        "                sampled_triplets.append(data[data['triplet_nr'].isin(sampled_triplet_ids)])\n",
        "\n",
        "        # Combine sampled triplets\n",
        "        sampled_data = pd.concat(sampled_triplets).reset_index(drop=True)\n",
        "\n",
        "        # Step 4: Enforce exactly 700 unique triplets (2100 rows)\n",
        "        unique_triplet_ids = sampled_data['triplet_nr'].drop_duplicates().head(sample_size)\n",
        "        sampled_data = sampled_data[sampled_data['triplet_nr'].isin(unique_triplet_ids)]\n",
        "\n",
        "        return sampled_data\n",
        "\n",
        "\n",
        "\n",
        "    final_sample = sample_triplets(data, sample_size, num_bins)\n",
        "\n",
        "    # Step 4:\n",
        "    triplet_avg = final_sample.groupby('triplet_nr')['measure_1'].mean().reset_index(name='triplet_avg_measure_1')\n",
        "\n",
        "    # Merge back to keep triplet-level averages\n",
        "    final_sample = final_sample.merge(triplet_avg, on='triplet_nr')\n",
        "    final_sample_increasing = final_sample.sort_values(by='triplet_avg_measure_1').reset_index(drop=True)\n",
        "    final_sample_decreasing = final_sample.sort_values(by='triplet_avg_measure_1', ascending=False).reset_index(drop=True)\n",
        "\n",
        "    # Print bin distributions for the final samples\n",
        "    increasing_bins = final_sample_increasing.groupby('range_bin')['triplet_nr'].nunique()\n",
        "    print(f\"Distribution of bins in increasing order sample:\\n{increasing_bins}\")\n",
        "    print(f\"Sampled {sample_size} triplets and returned two ordered DataFrames.\")\n",
        "\n",
        "    return final_sample_increasing, final_sample_decreasing\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the function with the basic measure\n",
        "sample_increasing, sample_decreasing = process_snli_dataset_with_measures(file_path='/content/sampled_snli_10000.csv')\n",
        "\n",
        "# Display the outputs\n",
        "print(\"Sample ordered by increasing triplet average:\")\n",
        "print(sample_increasing.head())\n",
        "\n",
        "#print(\"\\nSample ordered by decreasing triplet average:\")\n",
        "#print(sample_decreasing.head())\n",
        "sample_increasing.to_csv('sample_increasing.csv', index=False)\n",
        "#sample_decreasing.to_csv('sample_decreasing.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b91IHSpXtQdE",
        "outputId": "28605fcf-481c-4f8b-f800-366b0e24ee0a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded: 30000 rows\n",
            "Distribution of triplets across bins:\n",
            "range_bin\n",
            "0    5495\n",
            "1    6368\n",
            "2    1362\n",
            "3     179\n",
            "4      26\n",
            "5       5\n",
            "6       4\n",
            "Name: triplet_nr, dtype: int64\n",
            "Distribution of bins in increasing order sample:\n",
            "range_bin\n",
            "0    546\n",
            "1    662\n",
            "2    157\n",
            "3     27\n",
            "4      5\n",
            "Name: triplet_nr, dtype: int64\n",
            "Sampled 700 triplets and returned two ordered DataFrames.\n",
            "Sample ordered by increasing triplet average:\n",
            "                premise                      hypothesis  label  triplet_nr  \\\n",
            "0         A boy points.                The boy pointed.      0      168707   \n",
            "1         A boy points.  The boy pointed at the person.      1      168707   \n",
            "2         A boy points.    The girl pointed towards me.      2      168707   \n",
            "3  A man petting a dog.             A man pets his dog.      1       78078   \n",
            "4  A man petting a dog.           A man pets an animal.      0       78078   \n",
            "\n",
            "   measure_1  range_bin  triplet_avg_measure_1  \n",
            "0         29          0              37.666667  \n",
            "1         43          0              37.666667  \n",
            "2         41          0              37.666667  \n",
            "3         39          0              42.333333  \n",
            "4         41          0              42.333333  \n"
          ]
        }
      ]
    }
  ]
}